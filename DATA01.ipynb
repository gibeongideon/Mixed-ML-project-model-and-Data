{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>X</th>\n",
       "      <th>HT1</th>\n",
       "      <th>HT2</th>\n",
       "      <th>HTX</th>\n",
       "      <th>FS (0:0)</th>\n",
       "      <th>FS(0:0)2</th>\n",
       "      <th>FS(0:0)X</th>\n",
       "      <th>TEAMSd</th>\n",
       "      <th>...</th>\n",
       "      <th>G(0.5)U</th>\n",
       "      <th>G(1.5)O</th>\n",
       "      <th>G(1.5)U</th>\n",
       "      <th>G(2.5)O</th>\n",
       "      <th>G(2.5)U</th>\n",
       "      <th>G(3.5)O</th>\n",
       "      <th>G(3.5)U</th>\n",
       "      <th>G(4.5)O</th>\n",
       "      <th>G(4.5)U</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11869</th>\n",
       "      <td>1.80</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.70</td>\n",
       "      <td>16.75</td>\n",
       "      <td>VFL LISBON  VFL PARIS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22/11/2018 Thu 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870</th>\n",
       "      <td>1.55</td>\n",
       "      <td>6.75</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.45</td>\n",
       "      <td>8.00</td>\n",
       "      <td>VFL AMSTERDAM  VFL BRUSSELS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22/11/2018 Thu 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11871</th>\n",
       "      <td>2.30</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.15</td>\n",
       "      <td>37.00</td>\n",
       "      <td>VFL ROME  VFL LONDON</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>22/11/2018 Thu 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11872</th>\n",
       "      <td>2.85</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.15</td>\n",
       "      <td>6.00</td>\n",
       "      <td>VFL VIENNA  VFL COPENHAGEN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22/11/2018 Thu 00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11873</th>\n",
       "      <td>2.55</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.15</td>\n",
       "      <td>10.25</td>\n",
       "      <td>VFL ANKARA  VFL ATHENS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22/11/2018 Thu 00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1     2     X   HT1   HT2   HTX  FS (0:0)  FS(0:0)2  FS(0:0)X  \\\n",
       "11869  1.80  4.40  3.85  2.05  4.15  2.90      1.50      2.70     16.75   \n",
       "11870  1.55  6.75  3.80  2.10  7.50  2.10      1.50      3.45      8.00   \n",
       "11871  2.30  2.80  3.85  2.50  3.35  2.65      1.70      2.15     37.00   \n",
       "11872  2.85  2.80  2.95  3.20  3.40  2.15      2.20      2.15      6.00   \n",
       "11873  2.55  2.75  3.35  2.95  3.30  2.30      1.95      2.15     10.25   \n",
       "\n",
       "                            TEAMSd          ...          G(0.5)U  G(1.5)O  \\\n",
       "11869        VFL LISBON  VFL PARIS          ...              0.0     1.25   \n",
       "11870  VFL AMSTERDAM  VFL BRUSSELS          ...              0.0     1.45   \n",
       "11871         VFL ROME  VFL LONDON          ...              0.0     0.00   \n",
       "11872   VFL VIENNA  VFL COPENHAGEN          ...              6.0     1.75   \n",
       "11873       VFL ANKARA  VFL ATHENS          ...              0.0     1.40   \n",
       "\n",
       "       G(1.5)U  G(2.5)O  G(2.5)U  G(3.5)O  G(3.5)U  G(4.5)O  G(4.5)U  \\\n",
       "11869     3.55     1.85     1.85     3.40     1.25      0.0      0.0   \n",
       "11870     2.55     2.30     1.55     4.55     1.16      0.0      0.0   \n",
       "11871     0.00     1.55     2.35     2.35     1.55      4.1      1.2   \n",
       "11872     1.95     0.00     1.30     0.00     0.00      0.0      0.0   \n",
       "11873     2.75     2.25     1.55     4.35     1.18      0.0      0.0   \n",
       "\n",
       "                  timestamp  \n",
       "11869  22/11/2018 Thu 00:07  \n",
       "11870  22/11/2018 Thu 00:07  \n",
       "11871  22/11/2018 Thu 00:07  \n",
       "11872  22/11/2018 Thu 00:07  \n",
       "11873  22/11/2018 Thu 00:07  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df= pd.read_csv('/home/gsociety/Desktop/The Model/STORAGE/ANALIZ/liveDataG.csv')\n",
    "\n",
    "#dfR= pd.read_csv('/home/gsociety/Desktop/The Model/STORAGE/ANALIZ/resultDataG.csv')\n",
    "df= pd.read_csv('/home/gsociety/Desktop/DATA CENTRE/liveDataQ.csv')\n",
    "dfR= pd.read_csv('/home/gsociety/Desktop/DATA CENTRE/resultDataR.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teamCoded(S):\n",
    "    \n",
    "    cats=['MADRID', 'AMSTERDAM','BERLIN','LONDON','ROME','OSLO','LISBON','PARIS','BRUSSELS','ATHENS','STOCKHOLM',\n",
    "          'COPENHAGEN','VIENNA', 'ANKARA','EDINBURGH','BERN']\n",
    "\n",
    "    catsRev=[]\n",
    "    for tm in S:\n",
    "        if tm == cats[0]:\n",
    "            catsRev.append(1)\n",
    "        elif tm == cats[1]:\n",
    "            catsRev.append(2)\n",
    "        elif tm == cats[2]:\n",
    "            catsRev.append(3)\n",
    "        elif tm == cats[3]:\n",
    "            catsRev.append(4)\n",
    "        elif tm == cats[4]:\n",
    "            catsRev.append(5)\n",
    "        elif tm == cats[5]:\n",
    "            catsRev.append(6)\n",
    "        elif tm == cats[6]:\n",
    "            catsRev.append(7)\n",
    "        elif tm == cats[7]:\n",
    "            catsRev.append(8)\n",
    "        elif tm == cats[8]:\n",
    "            catsRev.append(9)\n",
    "        elif tm == cats[9]:\n",
    "            catsRev.append(10)\n",
    "        elif tm == cats[10]:\n",
    "            catsRev.append(11)\n",
    "        elif tm == cats[11]:\n",
    "            catsRev.append(12)\n",
    "        elif tm == cats[12]:\n",
    "            catsRev.append(13)\n",
    "        elif tm == cats[13]:\n",
    "            catsRev.append(14)\n",
    "        elif tm == cats[14]:\n",
    "            catsRev.append(15)\n",
    "        elif tm == cats[15]:\n",
    "            catsRev.append(16)\n",
    "    return catsRev\n",
    "\n",
    "def results(ps):\n",
    "    lp=[]\n",
    "    for x in ps:\n",
    "        h=x.replace(':','  ')[:1]\n",
    "        a=x.replace(':','  ')[1:]\n",
    "        if float(h) > float(a):\n",
    "            lp.append(1)\n",
    "\n",
    "        elif float(a) > float(h):\n",
    "            lp.append(2)\n",
    "        else:\n",
    "            lp.append(0)\n",
    "\n",
    "    return pd.Series(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split TEAMS into HOME & AWAY \n",
    "df['HOME']=pd.Series([x.split()[1] for x in df.TEAMSd])\n",
    "df['AWAY']=pd.Series([x.split()[3] for x in df.TEAMSd])\n",
    "df['TIMEdd']=pd.Series([x.split()[1] for x in df.TIMED])\n",
    "df['TIMEst']=pd.Series([x.split()[0] for x in df.timestamp])\n",
    "df['TIMEfc']=pd.Series([p[3:][5:8]+p[2:][:4]+p[:][:2] for p in df.TIMEst])\n",
    "#df['TIMEddR']=pd.Series([x.split()[1] for x in df.TIMEDdd])\n",
    "##\n",
    "'''\n",
    "lx=[]\n",
    "for x in df.TIMED:\n",
    "    p=x.split()[1].replace(':','.')\n",
    "    if float(p)> 1.00:\n",
    "        q=('0'+str((round((float(p.replace(':','.'))-1),2))).replace('.',':')+'0')[:5]\n",
    "    \n",
    "    else:\n",
    "        p=float(p)+24.00\n",
    "        q=str((float(str(p).replace(':','.'))-1)).replace('.',':') \n",
    "    lx.append(q)\n",
    "\n",
    "''' \n",
    "\n",
    "\n",
    "lx=[]\n",
    "for x in df.TIMED:\n",
    "    p=x.split()[1].replace(':','.')\n",
    "   # print('P:',p)\n",
    "    if float(p)> 1.59:\n",
    "        if float(p) < 12 and float(p) > 1.59:\n",
    "            #process tine between 2 -12 \n",
    "            q1=('0'+ str((round((float(p.replace(':','.'))-2),2))).replace('.',':')+'0')[:5]\n",
    "            if len(q1) == 4:\n",
    "                q = q1+ '0'\n",
    "            else:\n",
    "                q = q1\n",
    "          \n",
    "        else:\n",
    "            #process te rest of te time\n",
    "            q1=(str((round((float(p)-2),2))).replace('.',':')+'0')[:5]\n",
    "            if len(q1) == 4:\n",
    "                q = q1+ '0'\n",
    "            else:\n",
    "                q = q1\n",
    "                                          \n",
    "        \n",
    "      #  print('PQ:',p,q)\n",
    "    \n",
    "    else:\n",
    "        # process time b/w 00:00 to 2 :00\n",
    "        p1= float(p)\n",
    "        p= p1 +24.00                    \n",
    "        q1= str((float(str(p).replace(':','.'))-2)).replace('.',':')\n",
    "        #if q >= 24\n",
    "        if len(q1) ==4:\n",
    "            q = q1+ '0'\n",
    "        else:\n",
    "            q = q1\n",
    "       #print('PQ:',p1,q)\n",
    "      \n",
    "    lx.append(q)\n",
    "    \n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "df['TIMEr']=pd.Series(lx)\n",
    "\n",
    "df['TIMER']=df['TIMEfc']  + ' ' + df['TIMEdd']\n",
    "\n",
    "\n",
    "#Use teamCode FX to code HOME & AWAY collumns and crean new HOMECODE & AWAYCODE\n",
    "df['HOMECODE']=teamCoded(df['HOME'])\n",
    "df['AWAYCODE']=teamCoded(df['AWAY'])\n",
    "#df['TEAMSC']=df['HOMECODE'] + df['AWAYCODE']\n",
    "df['TC']=df['HOME']+' '+df['AWAY']\n",
    "colum=['TC','HOMECODE', 'AWAYCODE','TIMER','TIMED','TIMEr',\n",
    "'1', '2', 'X', 'HT1', 'HT2', 'HTX', 'FS (0:0)', 'FS(0:0)2', 'FS(0:0)X',\n",
    "        'G(0.5)O', 'G(0.5)U', 'G(1.5)O', 'G(1.5)U', 'G(2.5)O',\n",
    "       'G(2.5)U', 'G(3.5)O', 'G(3.5)U', 'G(4.5)O', 'G(4.5)U']\n",
    "data=df.reindex(columns=colum).fillna(0)\n",
    "#======================================================================\n",
    "dfR['TEAMSr']\n",
    "dfR['TEAMSr']=pd.Series([x.upper() for x in dfR.TEAMSr])\n",
    "dfR['TEAMSr']=pd.Series([x.upper() for x in dfR.TEAMSr])\n",
    "#split TEAMS into HOME & AWAY \n",
    "dfR['HOME']=pd.Series([x.split()[1] for x in dfR.TEAMSr])\n",
    "dfR['AWAY']=pd.Series([x.split()[4] for x in dfR.TEAMSr])\n",
    "dfR['TIMEr']=pd.Series([x.split()[1] for x in dfR.TIMER])\n",
    "#Use teamCode FX to code HOME & AWAY collumns and crean new HOMECODE & AWAYCODE\n",
    "dfR['TC']=dfR['HOME']+' '+dfR['AWAY']\n",
    "\n",
    "dfR['HOMECODE']=teamCoded(dfR['HOME'])\n",
    "dfR['AWAYCODE']=teamCoded(dfR['AWAY'])\n",
    "#dfR['TEAMSC']=dfR['HOMECODE'] + dfR['AWAYCODE']\n",
    "#teamCode(dfR['HOME'])\n",
    "\n",
    "\n",
    "    \n",
    "dfR['FT_Goals']=pd.Series([str(x).replace(':','  ')[:] for x in dfR.FTR])\n",
    "dfR['HT_Goals']=pd.Series([str(x).replace(':','  ')[:] for x in dfR.HTR])\n",
    "dfR['FT_home_goals']=pd.Series([str(x).replace(':','  ')[:1] for x in dfR.FTR])\n",
    "dfR['FT_away_goals']=pd.Series([str(x).replace(':','  ')[1:] for x in dfR.FTR])\n",
    "dfR['HT_home_goals']=pd.Series([str(x).replace(':','  ')[:1] for x in dfR.HTR])\n",
    "dfR['HT_away_goals']=pd.Series([str(x).replace(':','  ')[1:] for x in dfR.HTR])\n",
    "\n",
    "dfR['FT_Results_1_0_2']=results(dfR['FT_Goals'])\n",
    "dfR['HT_Results_1_0_2']=results(dfR['HT_Goals'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colum=['TC','HOMECODE', 'AWAYCODE','TIMEr','HTR', 'FTR', 'HT_home_goals', 'HT_away_goals',\n",
    "       'FT_home_goals','FT_away_goals','HT_Results_1_0_2','FT_Results_1_0_2']\n",
    "resu= dfR.reindex(columns=colum).fillna(0)#.values\n",
    "\n",
    "#Dumies\n",
    "##dummiesf = pd.get_dummies(datasF.FT_Results_1_0_2, prefix='FT_Results')\n",
    "#dummiesh = pd.get_dummies(dfR.HT_Results_1_0_2, prefix='HT_Results')\n",
    "##resu= datasF.drop('FT_Results_1_0_2', axis=1).join(dummiesf)\n",
    "#dataF= dfR.drop('HT_Results_1_0_2', axis=1).join(dummiesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.merge(resu,data,on=('TC','TIMEr','HOMECODE','AWAYCODE'))\n",
    "#f=pd.merge(resu,data,on=('TIMEr','AWAYCODE'))\n",
    "#f[200:600]\n",
    "f.drop_duplicates()#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/gsociety/Desktop/DATA CENTRE/ProcessedDATA1.csv', 'a') as file:\n",
    "    f.to_csv(file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cols = ['HOMECODE', 'AWAYCODE', '1', 'X', '2', 'HT1', 'HTX', 'HT2',\n",
    "      # 'FS (0:0)', 'FS(0:0)X', 'FS(0:0)2', 'G(0.5)O', 'G(0.5)U', 'G(1.5)O',\n",
    "     #  'G(1.5)U', 'G(2.5)O', 'G(2.5)U', 'G(3.5)O', 'G(3.5)U', 'G(4.5)O',\n",
    "      # 'G(4.5)U','HTR', 'FTR']\n",
    "\n",
    "model_cols=['HOMECODE', 'AWAYCODE', '1',\n",
    "       '2', 'X', 'HT1', 'HT2', 'HTX', 'FS (0:0)', 'FS(0:0)2', 'FS(0:0)X',\n",
    "       'G(0.5)O', 'G(0.5)U', 'G(1.5)O', 'G(1.5)U', 'G(2.5)O', 'G(2.5)U',\n",
    "       'G(3.5)O', 'G(3.5)U', 'G(4.5)O', 'G(4.5)U','FT_Results_1_0_2']\n",
    "\n",
    "\n",
    "#model_data=f.loc[:, model_cols].head()\n",
    "#model_data.values\n",
    "\n",
    "mod_data=f.reindex(columns=model_cols).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataR=mod_data.values\n",
    "#mod_data.T\n",
    "dataR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=dataR[:,0:21][:12000]\n",
    "y_train= dataR[:,21][:12000]\n",
    "X_test=dataR[:,0:21][12000]\n",
    "y_test= dataR[:,21][12000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibilit\n",
    "import matplotlib.pyplot as plt\n",
    "# network and training\n",
    "NB_EPOCH = 1\n",
    "BATCH_SIZE = 30\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 3\n",
    "OPTIMIZER = Adam() \n",
    "N_HIDDEN1= 100\n",
    "N_HIDDEN2= 500\n",
    "VALIDATION_SPLIT=0.2 \n",
    "DROPOUT = 0.2\n",
    "RESHAPED = 21\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 25\n",
    "X_test /= 25\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# M_HIDDEN hidden layers 10 outputs\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN1, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(N_HIDDEN2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1]*100)\n",
    "model.save('N_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the ConvNet\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, kernel_size=5, padding=\"same\",input_shape=input_shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(1, 2), strides=(2, 2)))\n",
    "# CONV => RELU => POOL\n",
    "        # CONV => RELU => POOl\n",
    "        model.add(Conv2D(50, kernel_size=5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(1, 2), strides=(2, 2)))\n",
    "    \n",
    "         # Flatten => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(50))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        # a softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vfl_data(t,p):\n",
    "    n=int(((100-p)/100)*t)\n",
    "    print('Train Data:',t-(t-n),'Test Data:',t-n)\n",
    "    dataTr=dataR[:n]\n",
    "    dataTe=dataR[n:]\n",
    "    \n",
    "    x_train=dataTr[:,0:21]\n",
    "    x2_train=x_train.reshape(n,7,3)\n",
    "    x_train = x2_train[:, np.newaxis, :,:]\n",
    "    y_train= dataTr[:,21]\n",
    "\n",
    "\n",
    "    x1_test=dataTe[:,0:21]\n",
    "    x2_test=x1_test.reshape(t-n,7,3)\n",
    "    x_test = x2_test[:, np.newaxis, :,:]\n",
    "    y_test= dataTe[:,21]\n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=vfl_data(881,14.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 3\n",
    "BATCH_SIZE = 30\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.25\n",
    "ROWS,COLS = 7, 3 # input image dimensions\n",
    "NB_CLASSES = 3 # number of outputs = number of digits\n",
    "INPUT_SHAPE = (1, ROWS, COLS)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)=vfl_data(881,10.7)\n",
    "\n",
    "# consider them as float and normalize\n",
    "X_train= (x_train.astype('float32'))/25\n",
    "X_test= (x_test.astype('float32'))/25\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the optimizer and modeL\n",
    "model = LeNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train,batch_size=BATCH_SIZE, epochs=NB_EPOCH,verbose=VERBOSE,\n",
    "                    validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "model.save('g_model.h5')\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy percentage:', round(score[1]*100,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as JSON \n",
    "json_string = model.to_json()\n",
    "# save as YAML \n",
    "yaml_string = model.to_yaml()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from JSON: \\\\\n",
    "from keras.models import model_from_json \n",
    "model = model_from_json(json_string) \n",
    "# model reconstruction from YAML \n",
    "model = model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model.save('my_model.h5')\n",
    "# creates a HDF5 file 'my_model.h5' \n",
    "#del model\n",
    "# deletes the existing model\n",
    "# returns a compiled model identical to the previous one\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,patience=0, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}): \n",
    "        self.losses = []     \n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):         \n",
    "        self.losses.append(logs.get('loss'))\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_dim=784, init='uniform'))\n",
    "        model.add(Activation('softmax')) \n",
    "        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "        history = LossHistory()\n",
    "        model.fit(X_train,Y_train, batch_size=128, nb_epoch=20,  verbose=0, callbacks=[history])\n",
    "        print(history.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
